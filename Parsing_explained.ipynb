{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Импорт библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import glob\n",
    "import string\n",
    "import nltk\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Отсев невалидных данных и определение валидных\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Utils():\n",
    "    root_directory = os.chdir('c:/Users/iZiPC.by/notebooks/parser/')# input path\n",
    "    list_of_files = glob.glob('**/*.txt', recursive=True)\n",
    "    invalid_parsing = []\n",
    "    trash = ['Волковыск-1.txt','Волковыск.txt','Вороново-1.txt',\n",
    "         'Вороново.txt', 'Черновик-1.txt', 'Черновик.txt']\n",
    "    for file in list_of_files:\n",
    "        try:\n",
    "             with open(file, encoding='utf-8') as f:\n",
    "                    num = f.readline()\n",
    "                    file_ = f.read()\n",
    "                    if num and file_:\n",
    "                        pass\n",
    "        except:\n",
    "            invalid_parsing.append(file)\n",
    "    for i in invalid_parsing:\n",
    "        list_of_files.remove(i)\n",
    "    for i in trash: \n",
    "        list_of_files.remove(i)\n",
    "\n",
    "\n",
    "list_of_files = Utils.list_of_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Определяем пустые списки, которые будут наполняться данными\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_ = []\n",
    "wbc_ = []\n",
    "hgb_ = []\n",
    "crea_ = []\n",
    "ldh_ = []\n",
    "sex_ = []\n",
    "crp_ = []\n",
    "tr = []\n",
    "bir = []\n",
    "ad = []\n",
    "dis = []\n",
    "ID_ = []\n",
    "dgs_ = []\n",
    "rf_ = []\n",
    "alt_ = []\n",
    "ast_ = []\n",
    "pct_ = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Методы, которые позволяют получить данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ID(num):\n",
    "  \"\"\"returns ID of the patient\"\"\"\n",
    "  for i in num.split():\n",
    "    for char in i.split():\n",
    "        if char.isnumeric():\n",
    "            try:\n",
    "                return int(char)\n",
    "            except:\n",
    "                return 'None'\n",
    "            \n",
    "            \n",
    "def treatment(file_):\n",
    "  \"\"\" returns srting of remedies used for the patient \"\"\"\n",
    "  for line in file_.split('\\n'):\n",
    "    if re.search('Провед.нное.лечение', line):  # Does the same thing as \"if 'hello' in line:\"\n",
    "        return(line.replace('Проведенное лечение:', \\\n",
    "                            '').replace('ЛФК', '').replace('ФТЛ', ''))\n",
    "    \n",
    "\n",
    "def born_adm_disch(file_):\n",
    "    \"\"\" finds all nessesary dates in the epicrisis\"\"\"\n",
    "    pattern = re.compile(\"(\\d{2}).(\\d{2}).(\\d{4})\") # check all dates\n",
    "    birthday, admission = pattern.findall(file_)[:2]\n",
    "    discharging = pattern.findall(file_)[-1]\n",
    "    try:\n",
    "        return ':'.join(birthday), ':'.join(admission), ':'.join(discharging)\n",
    "    except:\n",
    "        return 'None'\n",
    "\n",
    "\n",
    "pattern_diagnosis = ['Диагноз:','Диагноз клинический:','Диагноз', 'Д-з:',\n",
    "                     \"Диагноз заключительный:\"]\n",
    "def diagnosis_dirty(file_):\n",
    "  int_ = 0\n",
    "  for i in file_.split():\n",
    "    int_ += 1\n",
    "    if i in pattern_diagnosis:\n",
    "      return file_.split()[int_+1:int_+40]    \n",
    "  \n",
    "\n",
    "def crp(file_):\n",
    "  \"\"\"returns all crp values\"\"\"\n",
    "  file_= ''.join(file_.split())\n",
    "  file_ = re.sub(r'[ЦСC]РБ|\\w\\D(реактив.|реакт.|реак.)белок', 'С-реактивныйбелок', file_)\n",
    "  file_ = re.sub(r'\\d{,2}\\.\\d\\d\\.\\d{2,4}', '', file_)\n",
    "  file_ = re.sub(r'[():]', '', file_)\n",
    "  file_ = re.sub(r'(?<!С-реактивныйбелок)\\d\\d\\.\\d\\d', '', file_)\n",
    "  file_ = re.sub(r',', '.', file_)\n",
    "  pattern_1 = re.compile(r'(?:\\w\\Dреактивныйбелок|\\w\\Dреактивныйбелокдо)(\\d*\\.\\d+|\\d+)')\n",
    "  pattern_2 = pattern_1.findall(file_)\n",
    "  try:\n",
    "    if pattern_2:\n",
    "      return np.float_(pattern_2)\n",
    "    else:\n",
    "      return 'None'\n",
    "  except:\n",
    "    pass\n",
    "\n",
    "\n",
    "def gender(file_):\n",
    "  file_ = file_.title()\n",
    "  file_ = ''.join(file_.split())\n",
    "  file_ = re.sub(r'Диагноз.*', '', file_)\n",
    "  patt1 = re.compile(r'[А-Я](\\w{,19}(\\w|\\ич))[А-Я]\\w{,20}(вна)')\n",
    "  patt2 = patt1.findall(file_)\n",
    "  try:\n",
    "    if patt2:\n",
    "      return 'female'\n",
    "    else:\n",
    "      return 'male'\n",
    "  except:\n",
    "    pass\n",
    "  \n",
    "\n",
    "def ldh(file_):\n",
    "  file_= ''.join(file_.split())\n",
    "  file_ = file_.lower()\n",
    "  file_ = re.sub(r'[():]', '', file_)\n",
    "  file_ = re.sub(r'\\d{,2}\\.\\d\\d\\.\\d{2,4}', '', file_)\n",
    "  file_ = re.sub(r'\\wактатдегидрогеназ\\w', 'лдг', file_)\n",
    "  file_ = re.sub(r'(?<!лдг)\\d\\d\\.\\d\\d', '', file_)\n",
    "  patt1 = re.compile(r'(?<=лдг)\\d{,4}')\n",
    "  patt2 = patt1.findall(file_)\n",
    "  try:\n",
    "    if patt2:\n",
    "      return np.float_(patt2)\n",
    "    else:\n",
    "      return 'None'\n",
    "  except:\n",
    "    pass\n",
    "\n",
    "\n",
    "\n",
    "def cre(file_):\n",
    "  \"\"\"Returns all creatinine values\"\"\"\n",
    "  file_= ''.join(file_.split())  \n",
    "  file_ = file_.lower()\n",
    "  file_ = re.sub(r'[():]', '', file_)\n",
    "  file_ = re.sub(r'\\d{,2}\\.\\d\\d\\.\\d{2,4}', '', file_)\n",
    "  file_ = re.sub(r'(\\wреатини\\w|креатин|креат)(?![а-яА-Я,])', 'cre', file_)\n",
    "  file_ = re.sub(r'(?<!cre)\\d\\d\\.\\d\\d', '', file_)\n",
    "  patt1 = re.compile(r'(?<=cre)\\d{2,3}')\n",
    "  patt2 = patt1.findall(file_)\n",
    "  try:\n",
    "    if patt2:\n",
    "      return np.float_(patt2)\n",
    "    else:\n",
    "      return 'None'\n",
    "  except:\n",
    "    pass\n",
    "\n",
    "\n",
    "def hgb(file_):\n",
    "  \"\"\"returns list of str with level of hemoglobin\"\"\"\n",
    "  file_= ''.join(file_.split())  \n",
    "  file_ = file_.lower()\n",
    "  file_ = re.sub(r'[():]', '', file_)\n",
    "  patt = re.compile(r'гемоглобин|гемогл|гб|гем')\n",
    "  patt1 = re.sub(patt, r'hgb', file_)\n",
    "  patt2 = re.compile(r'(?<=hgb)\\d{2,3}')\n",
    "  all_hgb = patt2.findall(patt1)\n",
    "  try:\n",
    "    if all_hgb:\n",
    "      return np.float_(all_hgb)\n",
    "    else:\n",
    "      return 'None'\n",
    "  except:\n",
    "    pass\n",
    "\n",
    "\n",
    "def wbc(file_):\n",
    "  \"\"\"returns list of str with level of wbc\"\"\"\n",
    "  file_= ''.join(file_.split())\n",
    "  file_ = file_.lower()\n",
    "  file_ = re.sub(r'[():]', '', file_)\n",
    "  file_ = re.sub(r'10(\\*|[еe])9', '', file_)\n",
    "  file_ = re.sub(r'\\d{,2}\\.\\d\\d\\.\\d{2,4}', '', file_)\n",
    "  file_ = re.sub(r'\\Dбщийанализкрови', 'оак', file_)\n",
    "  file_ = re.sub(r'(?<=оак)гб\\d*,', '', file_)\n",
    "  file_ = re.sub(r',', '.', file_)\n",
    "  patt1 = re.compile(r'(?<=оак|wbc)(?:л|лейкоцит\\w)(\\d*\\.\\d+|\\d+)')\n",
    "  all_wbc = patt1.findall(file_)\n",
    "  try:\n",
    "    if all_wbc:\n",
    "      return np.float_(all_wbc)\n",
    "    else:\n",
    "      return 'None'\n",
    "  except:\n",
    "    pass\n",
    "\n",
    "\n",
    "def plt(file_):\n",
    "  \"\"\"returns list of str with level of plt\"\"\"\n",
    "  file_= ''.join(file_.split())\n",
    "  file_ = file_.lower()\n",
    "  file_ = re.sub(r'[():]', '', file_)\n",
    "  file_ = re.sub(r'10(\\*|[еe])9', '', file_)\n",
    "  file_ = re.sub(r'\\d{,2}\\.\\d\\d\\.\\d{2,4}', '', file_)\n",
    "  patt1 = re.compile(r'\\wромбоцит\\w|(?<![а-яА-Я])тр(?![а-яА-Я])')\n",
    "  file_ = re.sub(patt1, r'plt', file_)\n",
    "  file_ = re.sub(r'(?<!plt)\\d\\d\\.\\d\\d', '', file_)\n",
    "  patt2 = re.compile(r'(?<=plt)\\d{3}')\n",
    "  all_plt = patt2.findall(file_)\n",
    "  try:\n",
    "    if all_plt:\n",
    "      return np.float_(all_plt)\n",
    "    else:\n",
    "      return 'None'\n",
    "  except:\n",
    "    pass\n",
    "\n",
    "\n",
    "def rf(file_):\n",
    "  file_= ''.join(file_.split())  \n",
    "  file_ = re.sub(r'[а-яА-ЯёЁ]ДН[^Шш0-9]', 'ДН'.lower(), file_)\n",
    "  file_ = re.sub(r'(?<=ДН)[1iI]{3}|[Шш]', '3', file_)\n",
    "  file_ = re.sub(r'(?<=ДН)[1iI]{2}|1-2', '2', file_)\n",
    "  file_ = re.sub(r'(?<=ДН)[оoОO]', '0', file_)\n",
    "  patt1 = re.compile(r'(?<=ДН)\\d')\n",
    "  patt2 = patt1.findall(file_)\n",
    "  try:\n",
    "    if patt2:\n",
    "      return patt2\n",
    "    else:\n",
    "      return 0\n",
    "  except:\n",
    "      return 0\n",
    "\n",
    "\n",
    "\n",
    "def alt(file_):\n",
    "  file_= ''.join(file_.split())\n",
    "  file_ = file_.lower()\n",
    "  file_ = re.sub(r'[():]', '', file_)\n",
    "  file_ = re.sub(r'\\d{,2}\\.\\d\\d\\.\\d{2,4}', '', file_)\n",
    "  file_ = re.sub(r'\\wланинаминотрансфераз\\w|алат', 'алт', file_)\n",
    "  file_ = re.sub(r'(?<!алт)\\d\\d\\.\\d\\d', '', file_)\n",
    "  file_ = re.sub(r',', '.', file_) \n",
    "  patt1 = re.compile(r'(?<=алт)(\\d*\\.\\d+|\\d+)')\n",
    "  patt2 = patt1.findall(file_)\n",
    "  try:\n",
    "    if patt2:\n",
    "      return np.float_(patt2)\n",
    "    else:\n",
    "      return 'None'\n",
    "  except:\n",
    "    pass\n",
    "\n",
    "\n",
    "def ast(file_):\n",
    "  file_= ''.join(file_.split())\n",
    "  file_ = file_.lower()\n",
    "  file_ = re.sub(r'[():]', '', file_)\n",
    "  file_ = re.sub(r'\\d{,2}\\.\\d\\d\\.\\d{2,4}', '', file_)\n",
    "  file_ = re.sub(r'\\wспартатаминотрансфераз\\w|асат', 'аст', file_)\n",
    "  file_ = re.sub(r'(?<!аст)\\d\\d\\.\\d\\d', '', file_)\n",
    "  file_ = re.sub(r',', '.', file_)\n",
    "  patt1 = re.compile(r'(?<=аст)(\\d*\\.\\d+|\\d+)')\n",
    "  patt2 = patt1.findall(file_)\n",
    "  try:\n",
    "    if patt2:\n",
    "      return np.float_(patt2)\n",
    "    else:\n",
    "      return 'None'\n",
    "  except:\n",
    "    pass\n",
    "\n",
    "\n",
    "def pct(file_):\n",
    "  file_= ''.join(file_.split())\n",
    "  file_ = file_.lower()\n",
    "  file_ = re.sub(r'(?<=\\,\\d)\\,|\\.\\d{2}\\.\\d\\d\\.\\d{2,4}.', '', file_)\n",
    "  file_ = re.sub(r'\\d{,2}\\.\\d\\d\\.\\d{2,4}(\\.|)', '', file_)\n",
    "  file_ = re.sub(r'[–-]|[():<>=]', '', file_)\n",
    "  file_ = re.sub(r'менее', '', file_)\n",
    "  file_ = re.sub(r'от', '', file_)\n",
    "  file_ = re.sub(r'(\\wрокальцитони\\w|прокальцитон|прокальцит|прокальц|рст)(?![а-яА-Я,])', 'pct', file_)\n",
    "  file_ = re.sub(r',', '.', file_)\n",
    "  patt1 = re.compile(r'(?<=pct)(\\d*\\.\\d+|\\d+)')\n",
    "  patt2 = patt1.findall(file_)\n",
    "  try:\n",
    "    if patt2:\n",
    "      return np.float_(patt2)\n",
    "    else:\n",
    "      return 'None'\n",
    "  except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Запускаем методы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in list_of_files:\n",
    "    try:\n",
    "         with open(file, encoding='utf-8') as f:\n",
    "                num = f.readline()\n",
    "                file_ = f.read()\n",
    "                ID_.append(ID((num)))\n",
    "                tr.append(treatment((file_)))\n",
    "                bir.append(born_adm_disch(file_)[0])\n",
    "                ad.append(born_adm_disch(file_)[1])\n",
    "                dis.append(born_adm_disch(file_)[2])\n",
    "                dgs_.append(diagnosis_dirty((file_)))\n",
    "                crp_.append(crp(file_))\n",
    "                sex_.append(gender(file_))\n",
    "                ldh_.append(ldh(file_))\n",
    "                crea_.append(cre(file_))\n",
    "                hgb_.append(hgb(file_))\n",
    "                wbc_.append(wbc(file_))\n",
    "                plt_.append(plt(file_))\n",
    "                rf_.append(rf(file_))\n",
    "                alt_.append(alt(file_))\n",
    "                ast_.append(ast(file_))\n",
    "                pct_.append(pct(file_))\n",
    "    except:\n",
    "        print('stp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# !!! Работа со списками\n",
    "## 1) Начнём с диагнозов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnosis_cleaned =  []\n",
    "for diagnos in dgs_:\n",
    "    try:\n",
    "        diagnosis_cleaned.append(' '.join(diagnos))\n",
    "    except:\n",
    "        diagnosis_cleaned.append('None')\n",
    "        \n",
    "        \n",
    "        \n",
    "PUNCT_TO_REMOVE = string.punctuation\n",
    "def remove_punctuation(text):\n",
    "    \"\"\"custom function to remove the punctuation\"\"\"\n",
    "    return text.translate(str.maketrans('', '', PUNCT_TO_REMOVE))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "list_wo_punct = []\n",
    "for sent in diagnosis_cleaned:\n",
    "    try:\n",
    "        sent = remove_punctuation(sent.lower())\n",
    "        list_wo_punct.append(sent)\n",
    "    except:\n",
    "        pass\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таким образом, мы имеет список со строками без пунктуции, далее, нам надо найти ключевые слова, чтобы определить наличие или отсутствие конкретных заболеваний"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # - поиск коронавирусной инфекции. \n",
    "- если есть коронавирусная инфекция - 1, иначе - 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_list = []    \n",
    "for sent in list_wo_punct:\n",
    "    pattern = re.sub(r'covid19', 'covid', sent )\n",
    "    pattern = re.sub(r'коронавирусная', 'covid', pattern)\n",
    "    pattern = re.sub(r'короновирусная', 'covid', pattern)\n",
    "    pattern = re.sub(r'b342', 'covid', pattern)\n",
    "    pattern = re.sub(r'sarscov2', 'covid', pattern)\n",
    "    pattern = re.sub(r'торсков2', 'covid', pattern)\n",
    "    pattern_1 = re.compile(r'covid')\n",
    "    patt_2 = re.search(pattern_1, pattern)\n",
    "    try:\n",
    "        covid_list.append(patt_2)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    \n",
    "c =[]\n",
    "#если есть коронавирусная инфекция - 1, иначе - 0\n",
    "for i in covid_list:\n",
    "    if not i:\n",
    "        c.append(0)\n",
    "    else:\n",
    "        c.append(1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # - поиск пневмоний"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "pn_list = []\n",
    "for sent in list_wo_punct:\n",
    "    pattern = re.sub(r'пневмония', 'J18', sent )\n",
    "    pattern = re.sub(r'пне...ния', 'J18', pattern)\n",
    "    pattern = re.sub(r'внегоспитальная', 'J18', pattern)\n",
    "    pattern = re.sub(r'внебольничная', 'J18', pattern)\n",
    "    pattern_1 = re.compile(r'J18')\n",
    "    patt_2 = re.search(pattern_1, pattern)\n",
    "    try:\n",
    "        pn_list.append(patt_2)\n",
    "    except:\n",
    "        pass  \n",
    "    \n",
    "    \n",
    "p = []\n",
    "# если есть пневмония - 1, иначе - 0\n",
    "for i in pn_list:\n",
    "    if not i:\n",
    "        p.append(0)\n",
    "    else:\n",
    "        p.append(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Поиск ишемической болезни сердца"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 1247, 1: 977}"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ihd_list = []\n",
    "for sent in list_wo_punct:\n",
    "    pattern = re.sub(r'ссн', 'ИБС', sent )\n",
    "    pattern = re.sub(r'ибс', 'ИБС', pattern)\n",
    "    pattern = re.sub(r'атеросклеротический', 'ИБС', pattern)\n",
    "    pattern = re.sub(r'кардиосклероз', 'ИБС', pattern)\n",
    "    pattern = re.sub(r'фп', 'ИБС', pattern)\n",
    "    pattern = re.sub(r'фибрил....', 'ИБС', pattern)\n",
    "    pattern_1 = re.compile(r'ИБС')\n",
    "    patt_2 = re.search(pattern_1, pattern)\n",
    "    try:\n",
    "        ihd_list.append(patt_2)\n",
    "    except:\n",
    "        pass  \n",
    "# итого, обработаны все возможные паттерны    \n",
    "    \n",
    "ihd = []\n",
    "\n",
    "for i in ihd_list:\n",
    "    if not i:\n",
    "        ihd.append(0)\n",
    "    else:\n",
    "        ihd.append(1)\n",
    "\n",
    "d = {}\n",
    "for i in ihd:\n",
    "    d[i]=d.get(i, 0)+1\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итого мы имеет 977 пациентов с ИБС. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Поиск сахарного диабета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 2096, 1: 128}"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dm_list = []\n",
    "for sent in list_wo_punct:\n",
    "    pattern = re.sub(r'сд', 'СД', sent )\n",
    "    pattern = re.sub(r'сах.....', 'СД', pattern)\n",
    "    pattern = re.sub(r'д.абет', 'СД', pattern)\n",
    "    pattern_1 = re.compile(r'СД')\n",
    "    patt_2 = re.search(pattern_1, pattern)\n",
    "    try:\n",
    "        dm_list.append(patt_2)\n",
    "    except:\n",
    "        pass  \n",
    "    \n",
    "dm_ = []\n",
    "\n",
    "for i in dm_list:\n",
    "    if not i:\n",
    "        dm_.append(0)\n",
    "    else:\n",
    "        dm_.append(1)\n",
    "        \n",
    "d = {}\n",
    "for i in dm_:\n",
    "    d[i]=d.get(i, 0)+1\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "128 пациентов с сахарным диабетом"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Поиск ожирения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 2115, 1: 109}"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obes_list = []\n",
    "for sent in list_wo_punct:\n",
    "    pattern = re.sub(r'ожир.н..', 'ОЖИРЕНИЕ', sent )\n",
    "    pattern = re.sub(r'.нжо.', 'ОЖИРЕНИЕ', pattern)\n",
    "    \n",
    "    #pattern = re.sub(r'торсков2', 'covid', pattern)\n",
    "    pattern_1 = re.compile(r'ОЖИРЕНИЕ')\n",
    "    patt_2 = re.search(pattern_1, pattern)\n",
    "    #patt_2 = pattern_1.findall(''.join(pattern.split()))\n",
    "    try:\n",
    "        obes_list.append(patt_2)\n",
    "    except:\n",
    "        pass  \n",
    "    \n",
    "ob_ = []\n",
    "\n",
    "for i in obes_list:\n",
    "    if not i:\n",
    "        ob_.append(0)\n",
    "    else:\n",
    "        ob_.append(1)\n",
    "    \n",
    "d = {}\n",
    "for i in ob_:\n",
    "    d[i]=d.get(i, 0)+1\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 109 пациентов с ожирением"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Поиск обструктивной болезни лёгких"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 1833, 1: 391}"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "copd_list = []\n",
    "for sent in list_wo_punct:\n",
    "    pattern = re.sub(r'хобл', 'ХОБЛ', sent )\n",
    "    pattern = re.sub(r'другая обструктивная', 'ХОБЛ', pattern)\n",
    "    pattern = re.sub(r'j44', 'ХОБЛ', pattern)\n",
    "    pattern_1 = re.compile(r'ХОБЛ')\n",
    "    patt_2 = re.search(pattern_1, pattern)\n",
    "    try:\n",
    "        copd_list.append(patt_2)\n",
    "    except:\n",
    "        pass  \n",
    "\n",
    "\n",
    "copd_ = []\n",
    "for i in copd_list:\n",
    "    if not i:\n",
    "        copd_.append(0)\n",
    "    else:\n",
    "        copd_.append(1)    \n",
    "        \n",
    "d = {}\n",
    "for i in copd_:\n",
    "    d[i] = d.get(i, 0) + 1\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "391 пациент с хронической обструктивной болезнью лёгких"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Поиск бронхиальной астмы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 2065, 0: 159}"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ba_list = []\n",
    "for sent in list_wo_punct:\n",
    "  pattern = re.sub(r'бронхиальная', 'БА', sent )\n",
    "  pattern = re.sub(r'частично контролируемая', 'БА', pattern)\n",
    "  pattern = re.sub(r'\\sба\\s', 'БА', pattern )\n",
    "  pattern = re.sub(r'неконтролируемая', 'БА', pattern )\n",
    "  pattern_1 = re.compile(r'БА')\n",
    "  pattern_2 = re.search(pattern, sent)\n",
    "  try:\n",
    "    ba_list.append(pattern_2)\n",
    "  except:\n",
    "    pass\n",
    "ba = []\n",
    "for i in ba_list:\n",
    "    if not i:\n",
    "        ba.append(0)\n",
    "    else:\n",
    "        ba.append(1)\n",
    "\n",
    "d = {}\n",
    "for i in ba:\n",
    "    d[i] = d.get(i, 0) + 1\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "159 пациентов с бронхиальной астмой"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Определяем наличие дыхательной недостаточности у пациентов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.0: 1015, 1.0: 652, 2.0: 535, 3.0: 22}"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# нас интересует самый высокий уроведь ДН, т.к. у пациента при поступлении ДН может быть 2, а при выписке - 0,\n",
    "# о тяжести пациента мы будем судить по наибольшему значению\n",
    "rfl = []\n",
    "for i in rf_:\n",
    "    if i:\n",
    "        rfl.append(max(np.float_(i)))\n",
    "    else:\n",
    "        rfl.append(0)\n",
    "\n",
    "d = {}\n",
    "for i in rfl:\n",
    "    d[i] = d.get(i, 0) + 1\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "итого: по степеням дыхательной недостаточности мы имеем: {0.0: 1015, 1.0: 652, 2.0: 535, 3.0: 22}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Определение тяжести\n",
    "\n",
    "Пневмонии классифицируются на тяжёлые и нетяжёлые"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "gr_list = []\n",
    "for sent in list_wo_punct:\n",
    "  pattern = re.sub(r'среднетяж.л..', '', sent)\n",
    "  pattern = re.sub(r'ср.тяж.', '', sent)\n",
    "  pattern = re.sub(r'нетяж.л..', '', pattern)\n",
    "  pattern_1 = re.compile(r'тяж.л..')\n",
    "  pattern_2 = re.search(pattern_1, pattern)\n",
    "  try:\n",
    "    gr_list.append(pattern_2)\n",
    "  except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 2016, 1: 208}"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = []\n",
    "for i in gr_list:\n",
    "    if not i:\n",
    "        g.append(0)\n",
    "    else:\n",
    "        g.append(1)\n",
    "d = {}\n",
    "for i in g:\n",
    "    d[i] = d.get(i, 0) + 1\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итого у нас 208 тяжёлых пневмоний"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Работа с лечением. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# задаём словарь, в котором ключ - истинное название препарата, а значения - варианты названий ( коммерческих) и\n",
    "# названия с ошибками для обработки с помощью регулярных выражений\n",
    "\n",
    "dict_treatment = {'лизиноприл':'л.з.....ил|лизитар|лизинеоприл', \n",
    "                  'цефтриаксон':'три.....ф|цефт.....он|цефтриакосн', \n",
    "                   \"метопролол\":\"мет.....ол|эгилок\", \n",
    "                  \"фраксипарин\":\"фра......ин\",\n",
    "                  'тейкопланин': \"тей......ин.\",\n",
    "                  \"амброксол\": \"аброкол|амброко.|амб......|амброксолс|амброкосл|амброксолл|амброксолл|аброксол|амброксолл\", \n",
    "                  \"моксифлоксацин\": 'пле....кс.|мокс.......цин',\n",
    "                  \"молсидомин\":\"м.лсид...н\",\n",
    "                  \"спиронолактон\":\"сп.р.......он.|верош....н\",\n",
    "                 \"бисопролол\":\"б.с.пр..ол|бисопралдол|бикард|конкор\", \n",
    "                  \"лансопрозол\": \"лан......ол|ланс.зол\",\n",
    "                 \"меропенем\":\"мер....ем\",\n",
    "                  \"аторвастатин\": \"липромак|аторв.......\",\n",
    "                 \"дексаметазон\": \"декс.......н|дексаетазон\",\n",
    "                 \"левофлоксацин\": \"лев.......цин\",\n",
    "                 \"омепразол\": \"омез|омепр..ол\",\n",
    "                 \"азитромицин\": \"азит.......\",\n",
    "                 \"кандесартан\": \"к.с.рк\",\n",
    "                 \"амоксициллин\": \"амоксицилин|амо........н\",\n",
    "                 \"озельтамивир\": \"флустоп|озел.......р\",\n",
    "                 \"эноксапарин\": \"клексан|кл...ан\",\n",
    "                 \"имепенем\": \"им....ем\",\n",
    "                 \"клопидогрел\": \"клопидогрель|плавикс|клорпидогрель\",\n",
    "                 \"аспикард\": \"аспкиард|кардиомагнил|ас....рд\",\n",
    "                 \"амлодипин\":\"амл....ин\",\n",
    "                 \"амикацин\": \"ам.к...н\",\n",
    "                 \"индапамид\": \"индап|инд.....д\",\n",
    "                 \"беродуал\": \"бер.дуал|ипратропия.бромид\",\n",
    "                 \"ацетилцистеин\": \"ацецемед|асс|ацц|ацемед|ацецезон\",\n",
    "                 \"парацетамол\": \"парац.....л\",\n",
    "                 \"гидроксихлорохин\": \"плаквенил|имар.|иммар.\",\n",
    "                 \"метилпреднизолон\": \"медрол|м.дрол|метипред|диметилпреднизолон\",\n",
    "                 \"теофиллин\": \"теофилин|теотард|теофилл\",\n",
    "                 \"кларитромицин\": \"кларибацин|кла.......цин\",\n",
    "                 \"лозартан\": \"лазртан|л...ртан|л.риста\",\n",
    "                 \"валсартан\": \"валозартан|валз|вал....ан\",\n",
    "                 \"моксонидин\": \"м.кс.н.дин\",\n",
    "                 \"амиодарон\": \"ами.д.р.н|к.рд.рон\",\n",
    "                 \"полимиксин\": \"колистин|колистат|к.л.стат\",\n",
    "                 \"преднизолон\": \"преднезолон|пре.н.з.лон\",\n",
    "                 \"рамиприл\": \"рам.л...|рам.прил\",\n",
    "                 \"карбомазепин\": \"карб.м.з.п.н\",\n",
    "                 \"кетаролак\": \"кет.р.лак|кет.рол|кет.н.в\",\n",
    "                 \"гентамицин\": \"г.нт.мицин\",\n",
    "                 \"цефепим\": \"ц.ф.пим\",\n",
    "                 \"цефоперазон/сульбактам\": \"цеф.пер.зон|цеф.пер.зон.су.......\",\n",
    "                 \"тайгециклин\": \"тиг.циклин|та.г.циклин\",\n",
    "                 \"зопиклон\": \"з.п.клон|соне.|соне.с\"}\n",
    "\n",
    "cleaned_treatment = []\n",
    "for words in tr:\n",
    "    try:\n",
    "        for i, j in dict_treatment.items():\n",
    "            words = re.sub(j, i, words.lower())\n",
    "\n",
    "        cleaned_treatment.append(words)\n",
    "    except:\n",
    "        cleaned_treatment.append(\"None\")\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На выходе мы получили список с правильными названиями препаратов. Если нет - возвращаем \"Ноне\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Работа с анализами\n",
    "\n",
    "Мотивировочная часть:\n",
    "Прокальцитонин - показатель, который обладает довольно выской чувствительностью и специфичностью к наличию у пациента батериальной инфекции, т.о., если уровень прокальцитонина в пределах референтных значений - антибиотики пациенту не показаны. \n",
    "Таким образом, мы хотим знать уровень прокальцитонина у пациента при поступлении и максимальный прокальцитонин (нужны ли были ему антибиотики за всё время пребывания в больнице)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# при первичной оценке данных, оказалось, что имеет место уровень прокальцитонина 7.0, что невозможно. Это просто неправильный\n",
    "# парсинг. Поэтому заменим на 0.07\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-176-996c0f4efaac>:5: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if pct != 'None':\n"
     ]
    }
   ],
   "source": [
    "initial_pct = []\n",
    "max_pct = []\n",
    "try:\n",
    "    for pct in pct_:\n",
    "        if pct != 'None':\n",
    "            initial_pct.append(pct[0])\n",
    "            max_pct.append(max(pct))\n",
    "        else:\n",
    "            initial_pct.append(0)\n",
    "            max_pct.append(0)\n",
    "            \n",
    "except:\n",
    "    initial_pct.append(0)\n",
    "    max_pct.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.0"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(initial_pct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_pct_ = list(map(lambda x: x / 100 if x > 5 else x, initial_pct))\n",
    "max_pct_ = list(map(lambda x: x / 100 if x > 5 else x, max_pct))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(initial_pct_) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Показанием для антибиотикотерапии является уровень прокальцитонина более 0.5. Определим этот признак"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_4_ab = []\n",
    "for pct_i  in  max_pct_:\n",
    "    if pct_i > .49:\n",
    "        ind_4_ab.append(1)\n",
    "    else:\n",
    "        ind_4_ab.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2224"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ind_4_ab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отлично, проблема решена"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Поработаем с гемоглобином. В целом, нас будет интересовать наибольший уровень, чтобы определить наличие анемии "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "hgb__ = []\n",
    "try:\n",
    "    for hgb in hgb_:\n",
    "        if max(hgb) > 120:\n",
    "            hgb__.append(0)\n",
    "        else:\n",
    "            hgb__.append(1)\n",
    "                       \n",
    "except:\n",
    "    hgb__.append(0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hgb__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
